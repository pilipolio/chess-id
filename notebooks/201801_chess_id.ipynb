{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mbb\u001b[m\u001b[m    \u001b[34mbk\u001b[m\u001b[m    \u001b[34mbn\u001b[m\u001b[m    \u001b[34mbp\u001b[m\u001b[m    \u001b[34mbq\u001b[m\u001b[m    \u001b[34mbr\u001b[m\u001b[m    \u001b[34mempty\u001b[m\u001b[m \u001b[34mwb\u001b[m\u001b[m    \u001b[34mwk\u001b[m\u001b[m    \u001b[34mwn\u001b[m\u001b[m    \u001b[34mwp\u001b[m\u001b[m    \u001b[34mwq\u001b[m\u001b[m    \u001b[34mwr\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "data_path = '/Users/allaingu/Data/chess_id'\n",
    "train_data_path = '/Users/allaingu/Data/chess_id/train'\n",
    "\n",
    "! ls $train_data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "# https://discuss.pytorch.org/t/how-to-preprocess-input-for-pre-trained-networks/683/9\n",
    "normalize = transforms.Normalize(\n",
    "    mean=[0.485, 0.456, 0.406],\n",
    "    std=[0.229, 0.224, 0.225])\n",
    "\n",
    "train_dataset = datasets.folder.ImageFolder(\n",
    "    train_data_path,\n",
    "    transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 256, 256])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(\n",
       " ( 0 , 0 ,.,.) = \n",
       "   0.5707  0.5536  0.6392  ...   0.0741 -0.1314 -0.0972\n",
       "  -0.6794 -0.6965 -0.6623  ...   0.6221  0.7591  0.9303\n",
       "  -1.0904 -1.1247 -1.1760  ...   0.7248  1.1358  1.3070\n",
       "            ...             ⋱             ...          \n",
       "  -1.5528 -1.5014 -1.4672  ...   0.9132  1.3413  1.3927\n",
       "  -0.9877 -0.9877 -0.8507  ...   0.8104  1.2728  1.3413\n",
       "   0.4166  0.5707  0.5364  ...   0.5878  1.0673  1.1529\n",
       " \n",
       " ( 0 , 1 ,.,.) = \n",
       "   0.6429  0.6604  0.8004  ...   0.3277  0.0476  0.0301\n",
       "  -0.5826 -0.5826 -0.4776  ...   0.8880  0.9755  1.0805\n",
       "  -0.8978 -0.8978 -0.8978  ...   0.9580  1.3431  1.4657\n",
       "            ...             ⋱             ...          \n",
       "  -1.1429 -1.0903 -1.0378  ...   1.0280  1.4657  1.5182\n",
       "  -0.6877 -0.6527 -0.5126  ...   0.9230  1.3957  1.4657\n",
       "   0.6254  0.7829  0.7479  ...   0.6954  1.1856  1.2731\n",
       " \n",
       " ( 0 , 2 ,.,.) = \n",
       "   0.2173  0.2173  0.3742  ...  -0.0964 -0.3404 -0.3753\n",
       "  -0.9504 -0.9504 -0.8633  ...   0.4614  0.5834  0.6879\n",
       "  -1.2293 -1.2293 -1.2119  ...   0.5659  0.9668  1.0888\n",
       "            ...             ⋱             ...          \n",
       "  -1.4036 -1.3513 -1.2990  ...   0.5834  1.0191  1.0714\n",
       "  -0.9156 -0.9156 -0.7936  ...   0.4788  0.9494  1.0191\n",
       "   0.4091  0.5659  0.5136  ...   0.2522  0.7402  0.8274\n",
       " [torch.FloatTensor of size 1x3x256x256], \n",
       "  10\n",
       " [torch.LongTensor of size 1])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=1, shuffle=True)\n",
    "\n",
    "train_loader\n",
    "\n",
    "image_tensor, label  = next(iter(train_loader))\n",
    "print(image_tensor.shape)\n",
    "image_tensor, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bb',\n",
       " 'bk',\n",
       " 'bn',\n",
       " 'bp',\n",
       " 'bq',\n",
       " 'br',\n",
       " 'empty',\n",
       " 'wb',\n",
       " 'wk',\n",
       " 'wn',\n",
       " 'wp',\n",
       " 'wq',\n",
       " 'wr']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "from torch import nn\n",
    "\n",
    "model = models.alexnet(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential (\n",
       "  (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "  (1): ReLU (inplace)\n",
       "  (2): MaxPool2d (size=(3, 3), stride=(2, 2), dilation=(1, 1))\n",
       "  (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (4): ReLU (inplace)\n",
       "  (5): MaxPool2d (size=(3, 3), stride=(2, 2), dilation=(1, 1))\n",
       "  (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (7): ReLU (inplace)\n",
       "  (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (9): ReLU (inplace)\n",
       "  (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (11): ReLU (inplace)\n",
       "  (12): MaxPool2d (size=(3, 3), stride=(2, 2), dilation=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 256, 7, 7])\n",
      "torch.Size([1, 12544])\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "image_features = model.features(Variable(image_tensor))\n",
    "print(image_features.data.shape)\n",
    "\n",
    "print(image_features.view(image_features.size(0), 256 * 7 * 7).data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "\n",
    "class ImageClassifier(nn.Module):\n",
    "    LAST_LAYER_SIZE = 256 * 7 * 7\n",
    "    \n",
    "    def __init__(self, num_classes, alexnet_model):\n",
    "        super(ImageClassifier, self).__init__()\n",
    "        self.feature_model = alexnet_model.features\n",
    "        # Freeze those weights\n",
    "        for p in self.feature_model.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(self.LAST_LAYER_SIZE, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        features = self.feature_model(x)\n",
    "        flattened_features = features.view(features.size(0), -1)\n",
    "        return self.classifier(flattened_features)\n",
    "\n",
    "    \n",
    "class ImageClassifier(nn.Module):\n",
    "    LAST_LAYER_SIZE = 256 * 7 * 7\n",
    "    \n",
    "    def __init__(self, num_classes, alexnet_model):\n",
    "        super(ImageClassifier, self).__init__()\n",
    "        self.feature_model = alexnet_model.features\n",
    "        # Freeze those weights\n",
    "        for p in self.feature_model.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(self.LAST_LAYER_SIZE, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(1024, num_classes),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        features = self.feature_model(x)\n",
    "        flattened_features = features.view(features.size(0), -1)\n",
    "        return self.classifier(flattened_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "\n",
       "Columns 0 to 9 \n",
       "-0.7115 -0.7850 -0.7554 -0.2374  0.0073 -0.1187 -0.5541 -0.0968 -0.0438  0.9178\n",
       "\n",
       "Columns 10 to 12 \n",
       " 0.4998 -0.0048 -0.0571\n",
       "[torch.FloatTensor of size 1x13]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = ImageClassifier(num_classes=len(train_dataset.classes), alexnet_model=models.alexnet(pretrained=True))\n",
    "\n",
    "predictions = classifier(Variable(image_tensor))\n",
    "\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 2.7316\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      " 3.9307\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      " 3.2967\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      " 2.6984\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      " 1.3197\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      " 0.9563\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      " 3.3618\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      " 4.1733\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      " 1.4293\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      " 3.5195\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      " 1.5722\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      " 1.6089\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      " 2.5957\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      " 1.8126\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      " 1.3293\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      " 3.1214\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      " 2.8359\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      " 0.8738\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      " 0.8968\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      " 1.1159\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      " 0.6859\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      " 0.9195\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "1.00000e-04 *\n",
      "  5.2418\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      " 0.7246\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      " 0.8817\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      " 0.2440\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-48494d0c91ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# compute output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/gui/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-2675cb97ac74>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mflattened_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflattened_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/gui/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/gui/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/gui/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/gui/lib/python3.6/site-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/gui/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mthreshold\u001b[0;34m(input, threshold, value, inplace)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mThreshold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/gui/lib/python3.6/site-packages/torch/nn/_functions/thnn/auto.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, input, *params)\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m         \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlibrary_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "import operator\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=32, shuffle=True)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(filter(lambda p: p.requires_grad, classifier.parameters()), lr=0.01,\n",
    "                            momentum=0.9,\n",
    "                            weight_decay=1e-4)\n",
    "\n",
    "for i, (input, target) in enumerate(train_loader):\n",
    "    input_var = torch.autograd.Variable(input)\n",
    "    target_var = torch.autograd.Variable(target)\n",
    "\n",
    "    # compute output\n",
    "    output = classifier(input_var)\n",
    "    loss = criterion(output, target_var)\n",
    "    if i % 10 == 0:\n",
    "        print(loss.data[0])\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! wget https://raw.githubusercontent.com/pytorch/examples/master/imagenet/main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> using pre-trained model 'alexnet'\n",
      "Epoch: [0][0/162]\tTime 2.230 (2.230)\tData 0.383 (0.383)\tLoss 2.6642 (2.6642)\tPrec@1 17.188 (17.188)\tPrec@5 45.312 (45.312)\n",
      "Epoch: [0][10/162]\tTime 1.477 (1.560)\tData 0.000 (0.035)\tLoss 1.4033 (1.9735)\tPrec@1 81.250 (58.097)\tPrec@5 98.438 (84.801)\n",
      "Epoch: [0][20/162]\tTime 1.466 (1.514)\tData 0.000 (0.019)\tLoss 0.8170 (1.5640)\tPrec@1 82.812 (69.345)\tPrec@5 98.438 (90.253)\n",
      "Epoch: [0][30/162]\tTime 1.490 (1.504)\tData 0.000 (0.013)\tLoss 0.1957 (1.2364)\tPrec@1 92.188 (74.647)\tPrec@5 100.000 (93.246)\n",
      "Epoch: [0][40/162]\tTime 1.467 (1.503)\tData 0.000 (0.010)\tLoss 0.8900 (1.1346)\tPrec@1 89.062 (77.896)\tPrec@5 98.438 (94.588)\n",
      "Epoch: [0][50/162]\tTime 1.463 (1.499)\tData 0.000 (0.008)\tLoss 0.4776 (1.0806)\tPrec@1 93.750 (80.270)\tPrec@5 100.000 (95.558)\n",
      "Epoch: [0][60/162]\tTime 1.449 (1.495)\tData 0.000 (0.007)\tLoss 0.6770 (1.0502)\tPrec@1 90.625 (81.634)\tPrec@5 100.000 (96.260)\n",
      "Epoch: [0][70/162]\tTime 1.487 (1.490)\tData 0.000 (0.006)\tLoss 1.1414 (1.0304)\tPrec@1 87.500 (82.658)\tPrec@5 96.875 (96.655)\n",
      "Epoch: [0][80/162]\tTime 1.441 (1.487)\tData 0.000 (0.005)\tLoss 1.1495 (0.9990)\tPrec@1 89.062 (83.526)\tPrec@5 98.438 (97.010)\n",
      "Epoch: [0][90/162]\tTime 1.489 (1.485)\tData 0.000 (0.005)\tLoss 0.3613 (0.9475)\tPrec@1 90.625 (84.375)\tPrec@5 100.000 (97.321)\n",
      "Epoch: [0][100/162]\tTime 1.437 (1.481)\tData 0.000 (0.004)\tLoss 0.5609 (0.8926)\tPrec@1 90.625 (85.210)\tPrec@5 100.000 (97.556)\n",
      "Epoch: [0][110/162]\tTime 1.482 (1.479)\tData 0.000 (0.004)\tLoss 0.3927 (0.8554)\tPrec@1 90.625 (85.923)\tPrec@5 100.000 (97.748)\n",
      "Epoch: [0][120/162]\tTime 1.452 (1.478)\tData 0.000 (0.004)\tLoss 0.2179 (0.8160)\tPrec@1 96.875 (86.648)\tPrec@5 100.000 (97.934)\n",
      "Epoch: [0][130/162]\tTime 1.478 (1.476)\tData 0.000 (0.003)\tLoss 1.4398 (0.7993)\tPrec@1 89.062 (87.094)\tPrec@5 98.438 (98.080)\n",
      "Epoch: [0][140/162]\tTime 1.443 (1.475)\tData 0.000 (0.003)\tLoss 0.4147 (0.7829)\tPrec@1 92.188 (87.511)\tPrec@5 100.000 (98.183)\n",
      "Epoch: [0][150/162]\tTime 1.470 (1.473)\tData 0.000 (0.003)\tLoss 1.3993 (0.7565)\tPrec@1 84.375 (87.966)\tPrec@5 98.438 (98.282)\n",
      "Epoch: [0][160/162]\tTime 1.421 (1.471)\tData 0.000 (0.003)\tLoss 0.5313 (0.7263)\tPrec@1 95.312 (88.393)\tPrec@5 100.000 (98.389)\n",
      "Test: [0/3]\tTime 1.970 (1.970)\tLoss 1.1600 (1.1600)\tPrec@1 82.812 (82.812)\tPrec@5 100.000 (100.000)\n",
      " * Prec@1 38.919 Prec@5 86.486\n",
      "Epoch: [1][0/162]\tTime 1.948 (1.948)\tData 0.325 (0.325)\tLoss 0.1498 (0.1498)\tPrec@1 96.875 (96.875)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [1][10/162]\tTime 1.418 (1.493)\tData 0.000 (0.030)\tLoss 0.2680 (0.1953)\tPrec@1 95.312 (95.739)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [1][20/162]\tTime 1.445 (1.475)\tData 0.000 (0.016)\tLoss 0.0716 (0.1773)\tPrec@1 98.438 (96.503)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [1][30/162]\tTime 1.420 (1.465)\tData 0.000 (0.011)\tLoss 0.1971 (0.2346)\tPrec@1 96.875 (96.421)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [1][40/162]\tTime 1.432 (1.459)\tData 0.000 (0.008)\tLoss 0.0169 (0.2195)\tPrec@1 98.438 (96.532)\tPrec@5 100.000 (99.962)\n",
      "Epoch: [1][50/162]\tTime 1.445 (1.456)\tData 0.000 (0.007)\tLoss 0.0011 (0.2118)\tPrec@1 100.000 (96.722)\tPrec@5 100.000 (99.939)\n",
      "Epoch: [1][60/162]\tTime 1.440 (1.454)\tData 0.000 (0.006)\tLoss 0.0000 (0.1974)\tPrec@1 100.000 (96.952)\tPrec@5 100.000 (99.949)\n",
      "Epoch: [1][70/162]\tTime 1.440 (1.452)\tData 0.000 (0.005)\tLoss 0.0288 (0.1765)\tPrec@1 98.438 (97.073)\tPrec@5 100.000 (99.956)\n",
      "Epoch: [1][80/162]\tTime 1.413 (1.449)\tData 0.000 (0.004)\tLoss 0.2907 (0.1791)\tPrec@1 96.875 (97.184)\tPrec@5 100.000 (99.942)\n",
      "Epoch: [1][90/162]\tTime 1.423 (1.449)\tData 0.000 (0.004)\tLoss 0.0498 (0.1659)\tPrec@1 98.438 (97.304)\tPrec@5 100.000 (99.948)\n",
      "Epoch: [1][100/162]\tTime 1.429 (1.448)\tData 0.000 (0.004)\tLoss 0.2579 (0.1630)\tPrec@1 95.312 (97.370)\tPrec@5 100.000 (99.954)\n",
      "Epoch: [1][110/162]\tTime 1.462 (1.448)\tData 0.000 (0.003)\tLoss 0.3582 (0.1581)\tPrec@1 96.875 (97.410)\tPrec@5 100.000 (99.958)\n",
      "Epoch: [1][120/162]\tTime 1.455 (1.447)\tData 0.000 (0.003)\tLoss 0.0007 (0.1521)\tPrec@1 100.000 (97.559)\tPrec@5 100.000 (99.948)\n",
      "Epoch: [1][130/162]\tTime 1.421 (1.447)\tData 0.000 (0.003)\tLoss 0.0283 (0.1463)\tPrec@1 100.000 (97.710)\tPrec@5 100.000 (99.940)\n",
      "Epoch: [1][140/162]\tTime 1.421 (1.447)\tData 0.000 (0.003)\tLoss 0.2144 (0.1461)\tPrec@1 96.875 (97.651)\tPrec@5 100.000 (99.945)\n",
      "Epoch: [1][150/162]\tTime 1.422 (1.447)\tData 0.000 (0.003)\tLoss 0.0624 (0.1471)\tPrec@1 98.438 (97.610)\tPrec@5 100.000 (99.948)\n",
      "Epoch: [1][160/162]\tTime 1.433 (1.447)\tData 0.000 (0.002)\tLoss 0.1462 (0.1506)\tPrec@1 96.875 (97.525)\tPrec@5 100.000 (99.951)\n",
      "Test: [0/3]\tTime 1.932 (1.932)\tLoss 2.4756 (2.4756)\tPrec@1 71.875 (71.875)\tPrec@5 100.000 (100.000)\n",
      " * Prec@1 36.757 Prec@5 83.784\n",
      "Epoch: [2][0/162]\tTime 1.949 (1.949)\tData 0.331 (0.331)\tLoss 0.0438 (0.0438)\tPrec@1 96.875 (96.875)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [2][10/162]\tTime 1.439 (1.479)\tData 0.000 (0.030)\tLoss 0.0289 (0.0788)\tPrec@1 98.438 (98.438)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [2][20/162]\tTime 1.429 (1.455)\tData 0.000 (0.016)\tLoss 0.0952 (0.0799)\tPrec@1 98.438 (98.214)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [2][30/162]\tTime 1.428 (1.455)\tData 0.000 (0.011)\tLoss 0.1503 (0.0689)\tPrec@1 98.438 (98.488)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [2][40/162]\tTime 1.439 (1.451)\tData 0.000 (0.008)\tLoss 0.0512 (0.0772)\tPrec@1 96.875 (98.628)\tPrec@5 100.000 (99.962)\n",
      "Epoch: [2][50/162]\tTime 1.422 (1.449)\tData 0.000 (0.007)\tLoss 0.0274 (0.0643)\tPrec@1 98.438 (98.775)\tPrec@5 100.000 (99.969)\n",
      "Epoch: [2][60/162]\tTime 1.429 (1.446)\tData 0.000 (0.006)\tLoss 0.0001 (0.0579)\tPrec@1 100.000 (98.796)\tPrec@5 100.000 (99.974)\n",
      "Epoch: [2][70/162]\tTime 1.491 (1.444)\tData 0.000 (0.005)\tLoss 0.0099 (0.0649)\tPrec@1 100.000 (98.812)\tPrec@5 100.000 (99.956)\n",
      "Epoch: [2][80/162]\tTime 1.425 (1.444)\tData 0.000 (0.004)\tLoss 0.0082 (0.0607)\tPrec@1 100.000 (98.862)\tPrec@5 100.000 (99.961)\n",
      "Epoch: [2][90/162]\tTime 1.452 (1.444)\tData 0.000 (0.004)\tLoss 0.0004 (0.0571)\tPrec@1 100.000 (98.935)\tPrec@5 100.000 (99.966)\n",
      "Epoch: [2][100/162]\tTime 1.418 (1.444)\tData 0.000 (0.004)\tLoss 0.0001 (0.0545)\tPrec@1 100.000 (98.994)\tPrec@5 100.000 (99.969)\n",
      "Epoch: [2][110/162]\tTime 1.413 (1.443)\tData 0.000 (0.003)\tLoss 0.0000 (0.0509)\tPrec@1 100.000 (99.071)\tPrec@5 100.000 (99.972)\n",
      "Epoch: [2][120/162]\tTime 1.407 (1.443)\tData 0.000 (0.003)\tLoss 0.0620 (0.0503)\tPrec@1 98.438 (99.083)\tPrec@5 100.000 (99.974)\n",
      "Epoch: [2][130/162]\tTime 1.419 (1.442)\tData 0.000 (0.003)\tLoss 0.0176 (0.0479)\tPrec@1 98.438 (99.094)\tPrec@5 100.000 (99.976)\n",
      "Epoch: [2][140/162]\tTime 1.438 (1.441)\tData 0.000 (0.003)\tLoss 0.0083 (0.0458)\tPrec@1 100.000 (99.136)\tPrec@5 100.000 (99.967)\n",
      "Epoch: [2][150/162]\tTime 1.444 (1.442)\tData 0.000 (0.003)\tLoss 0.0774 (0.0437)\tPrec@1 98.438 (99.172)\tPrec@5 100.000 (99.969)\n",
      "Epoch: [2][160/162]\tTime 1.438 (1.441)\tData 0.000 (0.002)\tLoss 0.0049 (0.0423)\tPrec@1 100.000 (99.194)\tPrec@5 100.000 (99.971)\n",
      "Test: [0/3]\tTime 1.911 (1.911)\tLoss 0.6364 (0.6364)\tPrec@1 92.188 (92.188)\tPrec@5 100.000 (100.000)\n",
      " * Prec@1 44.865 Prec@5 88.649\n"
     ]
    }
   ],
   "source": [
    "! python  main.py --pretrained -a alexnet --lr 0.01 --batch-size 64 --epochs 3 $data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r--  1 allaingu  1202659905  11185717 15 Jan 09:25 model_best.pth.tar\r\n"
     ]
    }
   ],
   "source": [
    "!ls -ltr model_best.pth.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> using pre-trained model 'alexnet'\n",
      "=> loading checkpoint 'model_best.pth.tar'\n",
      "=> loaded checkpoint 'model_best.pth.tar' (epoch 3)\n",
      "Test: [0/3]\tTime 1.957 (1.957)\tLoss 0.6364 (0.6364)\tPrec@1 92.188 (92.188)\tPrec@5 100.000 (100.000)\n",
      " * Prec@1 44.865 Prec@5 88.649\n"
     ]
    }
   ],
   "source": [
    "! python  main.py -a alexnet --pretrained --batch-size 64 --epochs 1 --evaluate --resume model_best.pth.tar $data_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# with non-linearities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> using pre-trained model 'alexnet'\n",
      "Epoch: [0][0/162]\tTime 2.432 (2.432)\tData 0.374 (0.374)\tLoss 2.6699 (2.6699)\tPrec@1 3.125 (3.125)\tPrec@5 23.438 (23.438)\n",
      "Epoch: [0][10/162]\tTime 1.648 (1.742)\tData 0.000 (0.034)\tLoss 0.9338 (1.5843)\tPrec@1 65.625 (53.409)\tPrec@5 96.875 (77.557)\n",
      "Epoch: [0][20/162]\tTime 1.708 (1.707)\tData 0.000 (0.018)\tLoss 1.3779 (1.2944)\tPrec@1 67.188 (62.054)\tPrec@5 98.438 (86.086)\n",
      "Epoch: [0][30/162]\tTime 1.645 (1.692)\tData 0.000 (0.012)\tLoss 0.7119 (1.1375)\tPrec@1 76.562 (65.171)\tPrec@5 96.875 (89.819)\n",
      "Epoch: [0][40/162]\tTime 1.638 (1.682)\tData 0.000 (0.009)\tLoss 0.4872 (1.0014)\tPrec@1 76.562 (68.941)\tPrec@5 98.438 (91.959)\n",
      "Epoch: [0][50/162]\tTime 1.690 (1.680)\tData 0.000 (0.008)\tLoss 0.3597 (0.8977)\tPrec@1 87.500 (72.151)\tPrec@5 100.000 (93.321)\n",
      "Epoch: [0][60/162]\tTime 1.652 (1.677)\tData 0.000 (0.006)\tLoss 0.3216 (0.8341)\tPrec@1 87.500 (73.924)\tPrec@5 100.000 (94.314)\n",
      "Epoch: [0][70/162]\tTime 1.659 (1.671)\tData 0.000 (0.006)\tLoss 0.3172 (0.7822)\tPrec@1 90.625 (75.616)\tPrec@5 100.000 (95.004)\n",
      "Epoch: [0][80/162]\tTime 1.666 (1.669)\tData 0.000 (0.005)\tLoss 0.5924 (0.7415)\tPrec@1 79.688 (76.736)\tPrec@5 100.000 (95.583)\n",
      "Epoch: [0][90/162]\tTime 1.658 (1.670)\tData 0.000 (0.004)\tLoss 0.3571 (0.7125)\tPrec@1 87.500 (77.387)\tPrec@5 100.000 (96.016)\n",
      "Epoch: [0][100/162]\tTime 1.656 (1.669)\tData 0.000 (0.004)\tLoss 0.2442 (0.6886)\tPrec@1 87.500 (78.063)\tPrec@5 100.000 (96.380)\n",
      "Epoch: [0][110/162]\tTime 1.628 (1.667)\tData 0.000 (0.004)\tLoss 0.3780 (0.6621)\tPrec@1 84.375 (78.885)\tPrec@5 100.000 (96.692)\n",
      "Epoch: [0][120/162]\tTime 1.671 (1.666)\tData 0.000 (0.003)\tLoss 0.1547 (0.6414)\tPrec@1 93.750 (79.533)\tPrec@5 100.000 (96.940)\n",
      "Epoch: [0][130/162]\tTime 1.659 (1.665)\tData 0.000 (0.003)\tLoss 0.3265 (0.6243)\tPrec@1 90.625 (80.010)\tPrec@5 100.000 (97.149)\n",
      "Epoch: [0][140/162]\tTime 1.651 (1.663)\tData 0.000 (0.003)\tLoss 0.4552 (0.6106)\tPrec@1 82.812 (80.264)\tPrec@5 100.000 (97.318)\n",
      "Epoch: [0][150/162]\tTime 1.662 (1.663)\tData 0.001 (0.003)\tLoss 0.1999 (0.5977)\tPrec@1 92.188 (80.650)\tPrec@5 100.000 (97.444)\n",
      "Epoch: [0][160/162]\tTime 1.659 (1.662)\tData 0.000 (0.003)\tLoss 0.3673 (0.5854)\tPrec@1 87.500 (80.998)\tPrec@5 100.000 (97.603)\n",
      "Test: [0/3]\tTime 1.936 (1.936)\tLoss 0.2956 (0.2956)\tPrec@1 92.188 (92.188)\tPrec@5 100.000 (100.000)\n",
      " * Prec@1 42.162 Prec@5 85.946\n",
      "Epoch: [1][0/162]\tTime 2.209 (2.209)\tData 0.329 (0.329)\tLoss 0.1485 (0.1485)\tPrec@1 96.875 (96.875)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [1][10/162]\tTime 1.671 (1.681)\tData 0.000 (0.030)\tLoss 0.3520 (0.3646)\tPrec@1 89.062 (88.494)\tPrec@5 100.000 (99.716)\n",
      "Epoch: [1][20/162]\tTime 1.606 (1.651)\tData 0.000 (0.016)\tLoss 0.3199 (0.3504)\tPrec@1 90.625 (88.393)\tPrec@5 100.000 (99.851)\n",
      "Epoch: [1][30/162]\tTime 1.674 (1.641)\tData 0.000 (0.011)\tLoss 0.5173 (0.3398)\tPrec@1 82.812 (88.206)\tPrec@5 100.000 (99.899)\n",
      "Epoch: [1][40/162]\tTime 1.601 (1.633)\tData 0.000 (0.008)\tLoss 0.6566 (0.3451)\tPrec@1 81.250 (88.224)\tPrec@5 100.000 (99.886)\n",
      "Epoch: [1][50/162]\tTime 1.602 (1.629)\tData 0.000 (0.007)\tLoss 0.1653 (0.3391)\tPrec@1 93.750 (88.450)\tPrec@5 100.000 (99.816)\n",
      "Epoch: [1][60/162]\tTime 1.629 (1.630)\tData 0.000 (0.006)\tLoss 0.3082 (0.3413)\tPrec@1 89.062 (88.268)\tPrec@5 100.000 (99.821)\n",
      "Epoch: [1][70/162]\tTime 1.594 (1.629)\tData 0.000 (0.005)\tLoss 0.2151 (0.3403)\tPrec@1 93.750 (88.468)\tPrec@5 100.000 (99.846)\n",
      "Epoch: [1][80/162]\tTime 1.648 (1.629)\tData 0.000 (0.004)\tLoss 0.3810 (0.3321)\tPrec@1 89.062 (88.754)\tPrec@5 100.000 (99.846)\n",
      "Epoch: [1][90/162]\tTime 1.645 (1.628)\tData 0.000 (0.004)\tLoss 0.2853 (0.3338)\tPrec@1 90.625 (88.685)\tPrec@5 98.438 (99.845)\n",
      "Epoch: [1][100/162]\tTime 1.618 (1.627)\tData 0.000 (0.004)\tLoss 0.3008 (0.3325)\tPrec@1 92.188 (88.861)\tPrec@5 100.000 (99.861)\n",
      "Epoch: [1][110/162]\tTime 1.642 (1.627)\tData 0.000 (0.003)\tLoss 0.4314 (0.3325)\tPrec@1 85.938 (88.964)\tPrec@5 100.000 (99.859)\n",
      "Epoch: [1][120/162]\tTime 1.612 (1.627)\tData 0.000 (0.003)\tLoss 0.1249 (0.3307)\tPrec@1 95.312 (89.114)\tPrec@5 100.000 (99.845)\n",
      "Epoch: [1][130/162]\tTime 1.692 (1.626)\tData 0.000 (0.003)\tLoss 0.1414 (0.3270)\tPrec@1 95.312 (89.253)\tPrec@5 100.000 (99.845)\n",
      "Epoch: [1][140/162]\tTime 1.589 (1.624)\tData 0.000 (0.003)\tLoss 0.2572 (0.3206)\tPrec@1 89.062 (89.417)\tPrec@5 100.000 (99.845)\n",
      "Epoch: [1][150/162]\tTime 1.610 (1.623)\tData 0.000 (0.003)\tLoss 0.1718 (0.3140)\tPrec@1 90.625 (89.601)\tPrec@5 100.000 (99.855)\n",
      "Epoch: [1][160/162]\tTime 1.582 (1.622)\tData 0.000 (0.002)\tLoss 0.1785 (0.3060)\tPrec@1 92.188 (89.800)\tPrec@5 100.000 (99.864)\n",
      "Test: [0/3]\tTime 1.885 (1.885)\tLoss 0.2248 (0.2248)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\n",
      " * Prec@1 44.324 Prec@5 84.324\n",
      "Epoch: [2][0/162]\tTime 2.201 (2.201)\tData 0.324 (0.324)\tLoss 0.3561 (0.3561)\tPrec@1 89.062 (89.062)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [2][10/162]\tTime 1.603 (1.675)\tData 0.000 (0.030)\tLoss 0.3489 (0.3142)\tPrec@1 81.250 (88.920)\tPrec@5 100.000 (99.858)\n",
      "Epoch: [2][20/162]\tTime 1.608 (1.645)\tData 0.000 (0.016)\tLoss 0.1662 (0.2913)\tPrec@1 93.750 (89.435)\tPrec@5 100.000 (99.926)\n",
      "Epoch: [2][30/162]\tTime 1.596 (1.633)\tData 0.001 (0.011)\tLoss 0.4832 (0.2794)\tPrec@1 87.500 (90.373)\tPrec@5 100.000 (99.950)\n",
      "Epoch: [2][40/162]\tTime 1.610 (1.628)\tData 0.000 (0.008)\tLoss 0.2077 (0.2859)\tPrec@1 92.188 (90.244)\tPrec@5 100.000 (99.924)\n",
      "Epoch: [2][50/162]\tTime 1.700 (1.629)\tData 0.000 (0.007)\tLoss 0.3550 (0.2802)\tPrec@1 89.062 (90.411)\tPrec@5 100.000 (99.908)\n",
      "Epoch: [2][60/162]\tTime 1.621 (1.628)\tData 0.000 (0.006)\tLoss 0.3801 (0.2704)\tPrec@1 89.062 (90.753)\tPrec@5 100.000 (99.923)\n",
      "Epoch: [2][70/162]\tTime 1.594 (1.626)\tData 0.000 (0.005)\tLoss 0.2815 (0.2598)\tPrec@1 90.625 (91.109)\tPrec@5 100.000 (99.934)\n",
      "Epoch: [2][80/162]\tTime 1.595 (1.624)\tData 0.000 (0.004)\tLoss 0.3926 (0.2623)\tPrec@1 85.938 (91.165)\tPrec@5 100.000 (99.904)\n",
      "Epoch: [2][90/162]\tTime 1.594 (1.623)\tData 0.000 (0.004)\tLoss 0.1801 (0.2631)\tPrec@1 95.312 (91.071)\tPrec@5 100.000 (99.897)\n",
      "Epoch: [2][100/162]\tTime 1.656 (1.623)\tData 0.000 (0.004)\tLoss 0.2296 (0.2611)\tPrec@1 89.062 (91.151)\tPrec@5 100.000 (99.892)\n",
      "Epoch: [2][110/162]\tTime 1.634 (1.622)\tData 0.000 (0.003)\tLoss 0.1561 (0.2554)\tPrec@1 92.188 (91.357)\tPrec@5 100.000 (99.901)\n",
      "Epoch: [2][120/162]\tTime 1.598 (1.621)\tData 0.000 (0.003)\tLoss 0.1376 (0.2512)\tPrec@1 96.875 (91.503)\tPrec@5 100.000 (99.910)\n",
      "Epoch: [2][130/162]\tTime 1.588 (1.622)\tData 0.000 (0.003)\tLoss 0.1489 (0.2528)\tPrec@1 95.312 (91.400)\tPrec@5 100.000 (99.917)\n",
      "Epoch: [2][140/162]\tTime 1.575 (1.620)\tData 0.000 (0.003)\tLoss 0.1097 (0.2523)\tPrec@1 98.438 (91.478)\tPrec@5 100.000 (99.911)\n",
      "Epoch: [2][150/162]\tTime 1.599 (1.619)\tData 0.001 (0.003)\tLoss 0.1742 (0.2503)\tPrec@1 89.062 (91.484)\tPrec@5 100.000 (99.907)\n",
      "Epoch: [2][160/162]\tTime 1.587 (1.617)\tData 0.000 (0.002)\tLoss 0.3411 (0.2554)\tPrec@1 84.375 (91.333)\tPrec@5 100.000 (99.913)\n",
      "Test: [0/3]\tTime 1.870 (1.870)\tLoss 0.2425 (0.2425)\tPrec@1 92.188 (92.188)\tPrec@5 100.000 (100.000)\n",
      " * Prec@1 45.405 Prec@5 85.405\n"
     ]
    }
   ],
   "source": [
    "! python  main.py --pretrained -a alexnet --lr 0.01 --batch-size 64 --epochs 3 $data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> using pre-trained model 'alexnet'\n",
      "=> loading checkpoint 'model_best.pth.tar'\n",
      "=> loaded checkpoint 'model_best.pth.tar' (epoch 3)\n",
      "Test: [0/3]\tTime 1.905 (1.905)\tLoss 0.2425 (0.2425)\tPrec@1 92.188 (92.188)\tPrec@5 100.000 (100.000)\n",
      " * Prec@1 45.405 Prec@5 85.405\n"
     ]
    }
   ],
   "source": [
    "! python  main.py -a alexnet --pretrained --batch-size 64 --epochs 1 --evaluate --resume model_best.pth.tar $data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r--  1 allaingu  1202659905  112756735 15 Jan 09:57 ../../chess-id/src/chessid/non_lin_model_best.pth.tar\r\n"
     ]
    }
   ],
   "source": [
    "!ls -ltr  ../../chess-id/src/chessid/non_lin_model_best.pth.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best = torch.load('../../chess-id/src/chessid/non_lin_model_best.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r--  1 allaingu  1202659905  61318373 15 Jan 11:39 ../../chess-id/src/chessid/non_lin_model_only_best.pth.tar\r\n"
     ]
    }
   ],
   "source": [
    "torch.save(best['state_dict'], '../../chess-id/src/chessid/non_lin_model_only_best.pth.tar')\n",
    "!ls -ltr ../../chess-id/src/chessid/non_lin_model_only_best.pth.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "ImageClassifier(num_classes=13, alexnet_model=models.alexnet(pretrained=True)).load_state_dict(torch.load('../../chess-id/src/chessid/non_lin_model_only_best.pth.tar'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
